// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.5.1
// - protoc             v6.32.1
// source: ai_model.proto

package azdext

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	AiModelService_ListModels_FullMethodName                  = "/azdext.AiModelService/ListModels"
	AiModelService_ResolveModelDeployments_FullMethodName     = "/azdext.AiModelService/ResolveModelDeployments"
	AiModelService_ListUsages_FullMethodName                  = "/azdext.AiModelService/ListUsages"
	AiModelService_ListLocationsWithQuota_FullMethodName      = "/azdext.AiModelService/ListLocationsWithQuota"
	AiModelService_ListModelLocationsWithQuota_FullMethodName = "/azdext.AiModelService/ListModelLocationsWithQuota"
)

// AiModelServiceClient is the client API for AiModelService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
//
// AiModelService provides data-only operations for AI model catalog,
// deployment resolution, and quota/usage from Azure Cognitive Services.
// AzureContext is required for subscription_id.
type AiModelServiceClient interface {
	// ListModels returns available AI models, optionally filtered by filter.locations.
	// If filter.locations is empty, models are queried across all subscription locations.
	// Note: filter.locations controls which models are returned, but each returned model
	// keeps canonical metadata (including the full locations list).
	ListModels(ctx context.Context, in *ListModelsRequest, opts ...grpc.CallOption) (*ListModelsResponse, error)
	// ResolveModelDeployments returns all valid deployment configs for a model.
	// options.locations controls location scoping (empty means all subscription locations).
	// If quota is set, options.locations must contain exactly one location.
	ResolveModelDeployments(ctx context.Context, in *ResolveModelDeploymentsRequest, opts ...grpc.CallOption) (*ResolveModelDeploymentsResponse, error)
	// ListUsages returns quota/usage data for request.location.
	// request.location is required.
	ListUsages(ctx context.Context, in *ListUsagesRequest, opts ...grpc.CallOption) (*ListUsagesResponse, error)
	// ListLocationsWithQuota returns locations with sufficient quota.
	ListLocationsWithQuota(ctx context.Context, in *ListLocationsWithQuotaRequest, opts ...grpc.CallOption) (*ListLocationsWithQuotaResponse, error)
	// ListModelLocationsWithQuota returns locations where model has sufficient quota.
	// Response includes max remaining quota per location for label rendering.
	ListModelLocationsWithQuota(ctx context.Context, in *ListModelLocationsWithQuotaRequest, opts ...grpc.CallOption) (*ListModelLocationsWithQuotaResponse, error)
}

type aiModelServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewAiModelServiceClient(cc grpc.ClientConnInterface) AiModelServiceClient {
	return &aiModelServiceClient{cc}
}

func (c *aiModelServiceClient) ListModels(ctx context.Context, in *ListModelsRequest, opts ...grpc.CallOption) (*ListModelsResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListModelsResponse)
	err := c.cc.Invoke(ctx, AiModelService_ListModels_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aiModelServiceClient) ResolveModelDeployments(ctx context.Context, in *ResolveModelDeploymentsRequest, opts ...grpc.CallOption) (*ResolveModelDeploymentsResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ResolveModelDeploymentsResponse)
	err := c.cc.Invoke(ctx, AiModelService_ResolveModelDeployments_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aiModelServiceClient) ListUsages(ctx context.Context, in *ListUsagesRequest, opts ...grpc.CallOption) (*ListUsagesResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListUsagesResponse)
	err := c.cc.Invoke(ctx, AiModelService_ListUsages_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aiModelServiceClient) ListLocationsWithQuota(ctx context.Context, in *ListLocationsWithQuotaRequest, opts ...grpc.CallOption) (*ListLocationsWithQuotaResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListLocationsWithQuotaResponse)
	err := c.cc.Invoke(ctx, AiModelService_ListLocationsWithQuota_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aiModelServiceClient) ListModelLocationsWithQuota(ctx context.Context, in *ListModelLocationsWithQuotaRequest, opts ...grpc.CallOption) (*ListModelLocationsWithQuotaResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListModelLocationsWithQuotaResponse)
	err := c.cc.Invoke(ctx, AiModelService_ListModelLocationsWithQuota_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// AiModelServiceServer is the server API for AiModelService service.
// All implementations must embed UnimplementedAiModelServiceServer
// for forward compatibility.
//
// AiModelService provides data-only operations for AI model catalog,
// deployment resolution, and quota/usage from Azure Cognitive Services.
// AzureContext is required for subscription_id.
type AiModelServiceServer interface {
	// ListModels returns available AI models, optionally filtered by filter.locations.
	// If filter.locations is empty, models are queried across all subscription locations.
	// Note: filter.locations controls which models are returned, but each returned model
	// keeps canonical metadata (including the full locations list).
	ListModels(context.Context, *ListModelsRequest) (*ListModelsResponse, error)
	// ResolveModelDeployments returns all valid deployment configs for a model.
	// options.locations controls location scoping (empty means all subscription locations).
	// If quota is set, options.locations must contain exactly one location.
	ResolveModelDeployments(context.Context, *ResolveModelDeploymentsRequest) (*ResolveModelDeploymentsResponse, error)
	// ListUsages returns quota/usage data for request.location.
	// request.location is required.
	ListUsages(context.Context, *ListUsagesRequest) (*ListUsagesResponse, error)
	// ListLocationsWithQuota returns locations with sufficient quota.
	ListLocationsWithQuota(context.Context, *ListLocationsWithQuotaRequest) (*ListLocationsWithQuotaResponse, error)
	// ListModelLocationsWithQuota returns locations where model has sufficient quota.
	// Response includes max remaining quota per location for label rendering.
	ListModelLocationsWithQuota(context.Context, *ListModelLocationsWithQuotaRequest) (*ListModelLocationsWithQuotaResponse, error)
	mustEmbedUnimplementedAiModelServiceServer()
}

// UnimplementedAiModelServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedAiModelServiceServer struct{}

func (UnimplementedAiModelServiceServer) ListModels(context.Context, *ListModelsRequest) (*ListModelsResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListModels not implemented")
}
func (UnimplementedAiModelServiceServer) ResolveModelDeployments(context.Context, *ResolveModelDeploymentsRequest) (*ResolveModelDeploymentsResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ResolveModelDeployments not implemented")
}
func (UnimplementedAiModelServiceServer) ListUsages(context.Context, *ListUsagesRequest) (*ListUsagesResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListUsages not implemented")
}
func (UnimplementedAiModelServiceServer) ListLocationsWithQuota(context.Context, *ListLocationsWithQuotaRequest) (*ListLocationsWithQuotaResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListLocationsWithQuota not implemented")
}
func (UnimplementedAiModelServiceServer) ListModelLocationsWithQuota(context.Context, *ListModelLocationsWithQuotaRequest) (*ListModelLocationsWithQuotaResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ListModelLocationsWithQuota not implemented")
}
func (UnimplementedAiModelServiceServer) mustEmbedUnimplementedAiModelServiceServer() {}
func (UnimplementedAiModelServiceServer) testEmbeddedByValue()                        {}

// UnsafeAiModelServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to AiModelServiceServer will
// result in compilation errors.
type UnsafeAiModelServiceServer interface {
	mustEmbedUnimplementedAiModelServiceServer()
}

func RegisterAiModelServiceServer(s grpc.ServiceRegistrar, srv AiModelServiceServer) {
	// If the following call pancis, it indicates UnimplementedAiModelServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&AiModelService_ServiceDesc, srv)
}

func _AiModelService_ListModels_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListModelsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AiModelServiceServer).ListModels(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AiModelService_ListModels_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AiModelServiceServer).ListModels(ctx, req.(*ListModelsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AiModelService_ResolveModelDeployments_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ResolveModelDeploymentsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AiModelServiceServer).ResolveModelDeployments(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AiModelService_ResolveModelDeployments_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AiModelServiceServer).ResolveModelDeployments(ctx, req.(*ResolveModelDeploymentsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AiModelService_ListUsages_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListUsagesRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AiModelServiceServer).ListUsages(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AiModelService_ListUsages_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AiModelServiceServer).ListUsages(ctx, req.(*ListUsagesRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AiModelService_ListLocationsWithQuota_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListLocationsWithQuotaRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AiModelServiceServer).ListLocationsWithQuota(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AiModelService_ListLocationsWithQuota_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AiModelServiceServer).ListLocationsWithQuota(ctx, req.(*ListLocationsWithQuotaRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AiModelService_ListModelLocationsWithQuota_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListModelLocationsWithQuotaRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AiModelServiceServer).ListModelLocationsWithQuota(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AiModelService_ListModelLocationsWithQuota_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AiModelServiceServer).ListModelLocationsWithQuota(ctx, req.(*ListModelLocationsWithQuotaRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// AiModelService_ServiceDesc is the grpc.ServiceDesc for AiModelService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var AiModelService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "azdext.AiModelService",
	HandlerType: (*AiModelServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "ListModels",
			Handler:    _AiModelService_ListModels_Handler,
		},
		{
			MethodName: "ResolveModelDeployments",
			Handler:    _AiModelService_ResolveModelDeployments_Handler,
		},
		{
			MethodName: "ListUsages",
			Handler:    _AiModelService_ListUsages_Handler,
		},
		{
			MethodName: "ListLocationsWithQuota",
			Handler:    _AiModelService_ListLocationsWithQuota_Handler,
		},
		{
			MethodName: "ListModelLocationsWithQuota",
			Handler:    _AiModelService_ListModelLocationsWithQuota_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "ai_model.proto",
}
